{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Feature extraction\n",
        "In order to obtain more information about earthquakes, additional variables are calculated in order to develop a model that allows us to interpret these characteristics and determine whether a noise is an moonsquake/marsquake or not."
      ],
      "metadata": {
        "id": "gKp7dpMoLd3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We import the necessary libraries to process the data for each earthquake in the catalog (for both Mars and the Moon).\n",
        "from NASA_Seismic_Detection_COD import process_file, extract_features\n",
        "import os\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "97Ys1YtFL2T-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function *extract_features*, processes data from the .mseed files and creates a dataframe with important information such as:\n",
        "- Statistical Measures\n",
        "- Frequency-Based Features\n",
        "- Time-Domain Features\n",
        "- Energy-Based Features\n",
        "- Waveform Shape Features\n"
      ],
      "metadata": {
        "id": "M-oIYblvMjct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mars\n",
        "We processs training and test data an transform into one table."
      ],
      "metadata": {
        "id": "y27hY0ueNJ49"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Set"
      ],
      "metadata": {
        "id": "nSVAoMbBNdJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Appliying process_file to get if the information corresponds a marsquake or not\n",
        "\n",
        "# Create an empty list to store results\n",
        "results = []\n",
        "\n",
        "# Loop through all miniseed files in the directory\n",
        "directory_path='data/mars/training/data/'\n",
        "i=0\n",
        "for filename in os.listdir(directory_path):\n",
        "    if filename.endswith(\".mseed\"):\n",
        "        print(filename)\n",
        "        directory = directory_path + filename\n",
        "        processed_data = process_file(directory)  # Call the function\n",
        "        results.append(processed_data)\n",
        "        i=i+1\n",
        "\n",
        "# Create a DataFrame from the results list\n",
        "df_1 = pd.DataFrame(results, columns=[\"filename\", \"seismic_detected\"])\n",
        "print(\"Finished processing all files.\")\n",
        "print(\"Total of files analyzed: \"+str(i))"
      ],
      "metadata": {
        "id": "k1DI7YR-NHOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ng-zDrgALWPK"
      },
      "outputs": [],
      "source": [
        "# Appliying extract_features to get new features about each mseed file\n",
        "\n",
        "# Loop through all miniseed files in the directory\n",
        "directory_path='data/mars/training/data/'\n",
        "i=0\n",
        "for filename in os.listdir(directory_path):\n",
        "    if filename.endswith(\".mseed\"):\n",
        "        print('Processing: ', filename)\n",
        "        directory = directory_path + filename\n",
        "        if i==0:\n",
        "            df_2 = extract_features(directory) # Call the function\n",
        "            i = i+1\n",
        "        else:\n",
        "            df_add = extract_features(directory) # Call the function\n",
        "            df_2 = pd.concat([df_2,df_add])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We merge the two dataframes into one\n",
        "df_train = df_1.merge(df_2,on='filename',how='left')\n",
        "\n",
        "# And finally we create adittional features based on the data and planet\n",
        "df_train['test'] = 0\n",
        "df_train['source'] = 'mars'"
      ],
      "metadata": {
        "id": "HPQlpwNHOU45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Set"
      ],
      "metadata": {
        "id": "ED09V-tmPgnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Appliying process_file to get if the information corresponds a marsquake or not\n",
        "\n",
        "# Create an empty list to store results\n",
        "results = []\n",
        "\n",
        "# Loop through all miniseed files in the directory\n",
        "directory_path='data/mars/test/data/'\n",
        "i=0\n",
        "for filename in os.listdir(directory_path):\n",
        "    if filename.endswith(\".mseed\"):\n",
        "        print(filename)\n",
        "        directory = directory_path + filename\n",
        "        processed_data = process_file(directory)  # Call the function\n",
        "        results.append(processed_data)\n",
        "        i=i+1\n",
        "\n",
        "# Create a DataFrame from the results list\n",
        "df_1 = pd.DataFrame(results, columns=[\"filename\", \"seismic_detected\"])\n",
        "print(\"Finished processing all files.\")\n",
        "print(\"Total of files analyzed: \"+str(i))"
      ],
      "metadata": {
        "id": "pDkChMoSPdDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Appliying extract_features to get new features about each mseed file\n",
        "\n",
        "# Loop through all miniseed files in the directory\n",
        "directory_path='data/mars/test/data/'\n",
        "i=0\n",
        "for filename in os.listdir(directory_path):\n",
        "    if filename.endswith(\".mseed\"):\n",
        "        print('Processing: ', filename)\n",
        "        directory = directory_path + filename\n",
        "        if i==0:\n",
        "            df_2 = extract_features(directory) # Call the function\n",
        "            i = i+1\n",
        "        else:\n",
        "            df_add = extract_features(directory) # Call the function\n",
        "            df_2 = pd.concat([df_2,df_add])"
      ],
      "metadata": {
        "id": "pCiPyhxYPl-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We merge the two dataframes into one\n",
        "df_test = df_1.merge(df_2,on='filename',how='left')\n",
        "\n",
        "# And finally we create adittional features based on the data and planet\n",
        "df_test['test'] = 1\n",
        "df_test['source'] = 'mars'"
      ],
      "metadata": {
        "id": "iOt7VE0PPnVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df_train,df_test])\n",
        "df.to_csv('features_mars.csv',header=True,index=False)"
      ],
      "metadata": {
        "id": "-6jR11tSP07t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Moon\n",
        "We processs training and test data an transform into one table."
      ],
      "metadata": {
        "id": "jOCbLDMjQmmT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Set"
      ],
      "metadata": {
        "id": "GTCS_UCMQqoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Appliying process_file to get if the information corresponds a moonquake or not\n",
        "\n",
        "# Create an empty list to store results\n",
        "results = []\n",
        "\n",
        "# Loop through all miniseed files in the directory\n",
        "directory_path='data/lunar/training/data/S12_GradeA/'\n",
        "i=0\n",
        "for filename in os.listdir(directory_path):\n",
        "    if filename.endswith(\".mseed\"):\n",
        "        print(filename)\n",
        "        directory = directory_path + filename\n",
        "        processed_data = process_file(directory)  # Call the function\n",
        "        results.append(processed_data)\n",
        "        i=i+1\n",
        "\n",
        "# Create a DataFrame from the results list\n",
        "df_1 = pd.DataFrame(results, columns=[\"filename\", \"seismic_detected\"])\n",
        "print(\"Finished processing all files.\")\n",
        "print(\"Total of files analyzed: \"+str(i))"
      ],
      "metadata": {
        "id": "HbanjUKWQoRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Appliying extract_features to get new features about each mseed file\n",
        "\n",
        "# Loop through all miniseed files in the directory\n",
        "directory_path='data/lunar/training/data/S12_GradeA/'\n",
        "i=0\n",
        "for filename in os.listdir(directory_path):\n",
        "    if filename.endswith(\".mseed\"):\n",
        "        print('Processing: ', filename)\n",
        "        directory = directory_path + filename\n",
        "        if i==0:\n",
        "            df_2 = extract_features(directory) # Call the function\n",
        "            i = i+1\n",
        "        else:\n",
        "            df_add = extract_features(directory) # Call the function\n",
        "            df_2 = pd.concat([df_2,df_add])"
      ],
      "metadata": {
        "id": "YxZqzw7gQ4wA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We merge the two dataframes into one\n",
        "df_train = df_1.merge(df_2,on='filename',how='left')\n",
        "\n",
        "# And finally we create adittional features based on the data and planet\n",
        "df_train['test'] = 0\n",
        "df_train['source'] = 'moon'"
      ],
      "metadata": {
        "id": "s0MMJOAQRAcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Set"
      ],
      "metadata": {
        "id": "XWrZ_yhzRHnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Appliying process_file to get if the information corresponds a moonquake or not\n",
        "\n",
        "# Create an empty list to store results\n",
        "results = []\n",
        "\n",
        "# Loop through all miniseed files in the directory\n",
        "directory_path='data/lunar/test/data/S15_GradeA/'\n",
        "i=0\n",
        "for filename in os.listdir(directory_path):\n",
        "    if filename.endswith(\".mseed\"):\n",
        "        print(filename)\n",
        "        directory = directory_path + filename\n",
        "        processed_data = process_file(directory)  # Call the function\n",
        "        results.append(processed_data)\n",
        "        i=i+1\n",
        "\n",
        "# Create a DataFrame from the results list\n",
        "df_1 = pd.DataFrame(results, columns=[\"filename\", \"seismic_detected\"])\n",
        "print(\"Finished processing all files.\")\n",
        "print(\"Total of files analyzed: \"+str(i))\n",
        "\n",
        "\n",
        "###################################################################################################\n",
        "\n",
        "# Create an empty list to store results\n",
        "results = []\n",
        "\n",
        "# Loop through all miniseed files in the directory\n",
        "directory_path='data/lunar/test/data/S15_GradeB/'\n",
        "i=0\n",
        "for filename in os.listdir(directory_path):\n",
        "    if filename.endswith(\".mseed\"):\n",
        "        print(filename)\n",
        "        directory = directory_path + filename\n",
        "        processed_data = process_file(directory)  # Call the function\n",
        "        results.append(processed_data)\n",
        "        i=i+1\n",
        "\n",
        "# Create a DataFrame from the results list\n",
        "df_2 = pd.DataFrame(results, columns=[\"filename\", \"seismic_detected\"])\n",
        "print(\"Finished processing all files.\")\n",
        "print(\"Total of files analyzed: \"+str(i))\n",
        "\n",
        "\n",
        "###################################################################################################\n",
        "\n",
        "# Create an empty list to store results\n",
        "results = []\n",
        "\n",
        "# Loop through all miniseed files in the directory\n",
        "directory_path='data/lunar/test/data/S16_GradeA/'\n",
        "i=0\n",
        "for filename in os.listdir(directory_path):\n",
        "    if filename.endswith(\".mseed\"):\n",
        "        print(filename)\n",
        "        directory = directory_path + filename\n",
        "        processed_data = process_file(directory)  # Call the function\n",
        "        results.append(processed_data)\n",
        "        i=i+1\n",
        "\n",
        "# Create a DataFrame from the results list\n",
        "df_3 = pd.DataFrame(results, columns=[\"filename\", \"seismic_detected\"])\n",
        "print(\"Finished processing all files.\")\n",
        "print(\"Total of files analyzed: \"+str(i))\n",
        "\n",
        "\n",
        "###################################################################################################\n",
        "\n",
        "# Create an empty list to store results\n",
        "results = []\n",
        "\n",
        "# Loop through all miniseed files in the directory\n",
        "directory_path='data/lunar/test/data/S16_GradeB/'\n",
        "i=0\n",
        "for filename in os.listdir(directory_path):\n",
        "    if filename.endswith(\".mseed\"):\n",
        "        print(filename)\n",
        "        directory = directory_path + filename\n",
        "        processed_data = process_file(directory)  # Call the function\n",
        "        results.append(processed_data)\n",
        "        i=i+1\n",
        "\n",
        "# Create a DataFrame from the results list\n",
        "df_4 = pd.DataFrame(results, columns=[\"filename\", \"seismic_detected\"])\n",
        "print(\"Finished processing all files.\")\n",
        "print(\"Total of files analyzed: \"+str(i))"
      ],
      "metadata": {
        "id": "5hycZrEVRILY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_5 = pd.concat([df_1,df_2,df_3,df_4])"
      ],
      "metadata": {
        "id": "9TKH7O6tR1pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Appliying extract_features to get new features about each mseed file\n",
        "\n",
        "# Loop through all miniseed files in the directory\n",
        "directory_path='data/lunar/test/data/S15_GradeA/'\n",
        "i=0\n",
        "for filename in os.listdir(directory_path):\n",
        "    if filename.endswith(\".mseed\"):\n",
        "        print('Processing: ', filename)\n",
        "        directory = directory_path + filename\n",
        "        if i==0:\n",
        "            df_6 = extract_features(directory) # Call the function\n",
        "            i = i+1\n",
        "        else:\n",
        "            df_add = extract_features(directory) # Call the function\n",
        "            df_6 = pd.concat([df_6,df_add])\n",
        "\n",
        "\n",
        "###################################################################################################\n",
        "\n",
        "\n",
        "# Loop through all miniseed files in the directory\n",
        "directory_path='data/lunar/test/data/S15_GradeB/'\n",
        "i=0\n",
        "for filename in os.listdir(directory_path):\n",
        "    if filename.endswith(\".mseed\"):\n",
        "        print('Processing: ', filename)\n",
        "        directory = directory_path + filename\n",
        "        if i==0:\n",
        "            df_7 = extract_features(directory) # Call the function\n",
        "            i = i+1\n",
        "        else:\n",
        "            df_add = extract_features(directory) # Call the function\n",
        "            df_7 = pd.concat([df_7,df_add])\n",
        "\n",
        "\n",
        "###################################################################################################\n",
        "\n",
        "\n",
        "# Loop through all miniseed files in the directory\n",
        "directory_path='data/lunar/test/data/S16_GradeA/'\n",
        "i=0\n",
        "for filename in os.listdir(directory_path):\n",
        "    if filename.endswith(\".mseed\"):\n",
        "        print('Processing: ', filename)\n",
        "        directory = directory_path + filename\n",
        "        if i==0:\n",
        "            df_8 = extract_features(directory) # Call the function\n",
        "            i = i+1\n",
        "        else:\n",
        "            df_add = extract_features(directory) # Call the function\n",
        "            df_8 = pd.concat([df_8,df_add])\n",
        "\n",
        "\n",
        "###################################################################################################\n",
        "\n",
        "\n",
        "# Loop through all miniseed files in the directory\n",
        "directory_path='data/lunar/test/data/S16_GradeB/'\n",
        "i=0\n",
        "for filename in os.listdir(directory_path):\n",
        "    if filename.endswith(\".mseed\"):\n",
        "        print('Processing: ', filename)\n",
        "        directory = directory_path + filename\n",
        "        if i==0:\n",
        "            df_9 = extract_features(directory) # Call the function\n",
        "            i = i+1\n",
        "        else:\n",
        "            df_add = extract_features(directory) # Call the function\n",
        "            df_9 = pd.concat([df_9,df_add])"
      ],
      "metadata": {
        "id": "w7gl6_3_RsSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_10 = pd.concat([df_6,df_7,df_8,df_9])"
      ],
      "metadata": {
        "id": "5uyBa5IDSh_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We merge the two dataframes into one\n",
        "df_test = df_5.merge(df_10,on='filename',how='left')\n",
        "\n",
        "# And finally we create adittional features based on the data and planet\n",
        "df_test['test'] = 1\n",
        "df_test['source'] = 'moon'"
      ],
      "metadata": {
        "id": "gosQJBJXSoFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df_train,df_test])\n",
        "df.to_csv('features_moon.csv',header=True,index=False)"
      ],
      "metadata": {
        "id": "wFKqW4H2SuxR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
